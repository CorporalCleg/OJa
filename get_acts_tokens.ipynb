{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a28b2c1-ae69-49c8-9c83-cc384894f0d5",
   "metadata": {},
   "source": [
    "# Creating a dataset class with activations from the hooks and corresponding tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f28f3c85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: transformer_lens in c:\\users\\mqtyor\\ai_pc\\envs_general\\cmpttv\\lib\\site-packages (0.0.0)\n",
      "Requirement already satisfied: accelerate>=0.23.0 in c:\\users\\mqtyor\\ai_pc\\envs_general\\cmpttv\\lib\\site-packages (from transformer_lens) (0.27.2)\n",
      "Requirement already satisfied: beartype<0.15.0,>=0.14.1 in c:\\users\\mqtyor\\ai_pc\\envs_general\\cmpttv\\lib\\site-packages (from transformer_lens) (0.14.1)\n",
      "Requirement already satisfied: better-abc<0.0.4,>=0.0.3 in c:\\users\\mqtyor\\ai_pc\\envs_general\\cmpttv\\lib\\site-packages (from transformer_lens) (0.0.3)\n",
      "Requirement already satisfied: datasets>=2.7.1 in c:\\users\\mqtyor\\ai_pc\\envs_general\\cmpttv\\lib\\site-packages (from transformer_lens) (2.19.0)\n",
      "Requirement already satisfied: einops>=0.6.0 in c:\\users\\mqtyor\\ai_pc\\envs_general\\cmpttv\\lib\\site-packages (from transformer_lens) (0.8.0)\n",
      "Requirement already satisfied: fancy-einsum>=0.0.3 in c:\\users\\mqtyor\\ai_pc\\envs_general\\cmpttv\\lib\\site-packages (from transformer_lens) (0.0.3)\n",
      "Requirement already satisfied: jaxtyping>=0.2.11 in c:\\users\\mqtyor\\ai_pc\\envs_general\\cmpttv\\lib\\site-packages (from transformer_lens) (0.2.36)\n",
      "Requirement already satisfied: numpy>=1.24 in c:\\users\\mqtyor\\ai_pc\\envs_general\\cmpttv\\lib\\site-packages (from transformer_lens) (1.24.1)\n",
      "Requirement already satisfied: pandas>=1.1.5 in c:\\users\\mqtyor\\ai_pc\\envs_general\\cmpttv\\lib\\site-packages (from transformer_lens) (1.5.3)\n",
      "Requirement already satisfied: rich>=12.6.0 in c:\\users\\mqtyor\\ai_pc\\envs_general\\cmpttv\\lib\\site-packages (from transformer_lens) (13.3.3)\n",
      "Requirement already satisfied: sentencepiece in c:\\users\\mqtyor\\ai_pc\\envs_general\\cmpttv\\lib\\site-packages (from transformer_lens) (0.2.0)\n",
      "Requirement already satisfied: torch!=2.0,!=2.1.0,>=1.10 in c:\\users\\mqtyor\\ai_pc\\envs_general\\cmpttv\\lib\\site-packages (from transformer_lens) (2.5.1)\n",
      "Requirement already satisfied: tqdm>=4.64.1 in c:\\users\\mqtyor\\ai_pc\\envs_general\\cmpttv\\lib\\site-packages (from transformer_lens) (4.65.0)\n",
      "Requirement already satisfied: transformers>=4.37.2 in c:\\users\\mqtyor\\ai_pc\\envs_general\\cmpttv\\lib\\site-packages (from transformer_lens) (4.44.2)\n",
      "Requirement already satisfied: typeguard<5.0,>=4.2 in c:\\users\\mqtyor\\ai_pc\\envs_general\\cmpttv\\lib\\site-packages (from transformer_lens) (4.4.1)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\mqtyor\\ai_pc\\envs_general\\cmpttv\\lib\\site-packages (from transformer_lens) (4.12.2)\n",
      "Requirement already satisfied: wandb>=0.13.5 in c:\\users\\mqtyor\\ai_pc\\envs_general\\cmpttv\\lib\\site-packages (from transformer_lens) (0.16.6)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\mqtyor\\ai_pc\\envs_general\\cmpttv\\lib\\site-packages (from accelerate>=0.23.0->transformer_lens) (24.0)\n",
      "Requirement already satisfied: psutil in c:\\users\\mqtyor\\ai_pc\\envs_general\\cmpttv\\lib\\site-packages (from accelerate>=0.23.0->transformer_lens) (5.9.4)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\mqtyor\\ai_pc\\envs_general\\cmpttv\\lib\\site-packages (from accelerate>=0.23.0->transformer_lens) (6.0)\n",
      "Requirement already satisfied: huggingface-hub in c:\\users\\mqtyor\\ai_pc\\envs_general\\cmpttv\\lib\\site-packages (from accelerate>=0.23.0->transformer_lens) (0.25.0)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in c:\\users\\mqtyor\\ai_pc\\envs_general\\cmpttv\\lib\\site-packages (from accelerate>=0.23.0->transformer_lens) (0.4.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\mqtyor\\ai_pc\\envs_general\\cmpttv\\lib\\site-packages (from datasets>=2.7.1->transformer_lens) (3.14.0)\n",
      "Requirement already satisfied: pyarrow>=12.0.0 in c:\\users\\mqtyor\\ai_pc\\envs_general\\cmpttv\\lib\\site-packages (from datasets>=2.7.1->transformer_lens) (16.0.0)\n",
      "Requirement already satisfied: pyarrow-hotfix in c:\\users\\mqtyor\\ai_pc\\envs_general\\cmpttv\\lib\\site-packages (from datasets>=2.7.1->transformer_lens) (0.6)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in c:\\users\\mqtyor\\ai_pc\\envs_general\\cmpttv\\lib\\site-packages (from datasets>=2.7.1->transformer_lens) (0.3.8)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\mqtyor\\ai_pc\\envs_general\\cmpttv\\lib\\site-packages (from datasets>=2.7.1->transformer_lens) (2.28.1)\n",
      "Requirement already satisfied: xxhash in c:\\users\\mqtyor\\ai_pc\\envs_general\\cmpttv\\lib\\site-packages (from datasets>=2.7.1->transformer_lens) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in c:\\users\\mqtyor\\ai_pc\\envs_general\\cmpttv\\lib\\site-packages (from datasets>=2.7.1->transformer_lens) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.3.1,>=2023.1.0 in c:\\users\\mqtyor\\ai_pc\\envs_general\\cmpttv\\lib\\site-packages (from fsspec[http]<=2024.3.1,>=2023.1.0->datasets>=2.7.1->transformer_lens) (2024.3.1)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\mqtyor\\ai_pc\\envs_general\\cmpttv\\lib\\site-packages (from datasets>=2.7.1->transformer_lens) (3.8.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\mqtyor\\ai_pc\\envs_general\\cmpttv\\lib\\site-packages (from pandas>=1.1.5->transformer_lens) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\mqtyor\\ai_pc\\envs_general\\cmpttv\\lib\\site-packages (from pandas>=1.1.5->transformer_lens) (2023.3)\n",
      "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in c:\\users\\mqtyor\\ai_pc\\envs_general\\cmpttv\\lib\\site-packages (from rich>=12.6.0->transformer_lens) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\mqtyor\\ai_pc\\envs_general\\cmpttv\\lib\\site-packages (from rich>=12.6.0->transformer_lens) (2.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\mqtyor\\ai_pc\\envs_general\\cmpttv\\lib\\site-packages (from torch!=2.0,!=2.1.0,>=1.10->transformer_lens) (3.0)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\mqtyor\\ai_pc\\envs_general\\cmpttv\\lib\\site-packages (from torch!=2.0,!=2.1.0,>=1.10->transformer_lens) (3.0.3)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\mqtyor\\ai_pc\\envs_general\\cmpttv\\lib\\site-packages (from torch!=2.0,!=2.1.0,>=1.10->transformer_lens) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\mqtyor\\ai_pc\\envs_general\\cmpttv\\lib\\site-packages (from sympy==1.13.1->torch!=2.0,!=2.1.0,>=1.10->transformer_lens) (1.2.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\mqtyor\\ai_pc\\envs_general\\cmpttv\\lib\\site-packages (from tqdm>=4.64.1->transformer_lens) (0.4.6)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\mqtyor\\ai_pc\\envs_general\\cmpttv\\lib\\site-packages (from transformers>=4.37.2->transformer_lens) (2023.3.23)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in c:\\users\\mqtyor\\ai_pc\\envs_general\\cmpttv\\lib\\site-packages (from transformers>=4.37.2->transformer_lens) (0.19.1)\n",
      "Requirement already satisfied: importlib-metadata>=3.6 in c:\\users\\mqtyor\\ai_pc\\envs_general\\cmpttv\\lib\\site-packages (from typeguard<5.0,>=4.2->transformer_lens) (6.1.0)\n",
      "Requirement already satisfied: Click!=8.0.0,>=7.1 in c:\\users\\mqtyor\\ai_pc\\envs_general\\cmpttv\\lib\\site-packages (from wandb>=0.13.5->transformer_lens) (8.1.3)\n",
      "Requirement already satisfied: GitPython!=3.1.29,>=1.0.0 in c:\\users\\mqtyor\\ai_pc\\envs_general\\cmpttv\\lib\\site-packages (from wandb>=0.13.5->transformer_lens) (3.1.43)\n",
      "Requirement already satisfied: sentry-sdk>=1.0.0 in c:\\users\\mqtyor\\ai_pc\\envs_general\\cmpttv\\lib\\site-packages (from wandb>=0.13.5->transformer_lens) (2.0.1)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in c:\\users\\mqtyor\\ai_pc\\envs_general\\cmpttv\\lib\\site-packages (from wandb>=0.13.5->transformer_lens) (0.4.0)\n",
      "Requirement already satisfied: setproctitle in c:\\users\\mqtyor\\ai_pc\\envs_general\\cmpttv\\lib\\site-packages (from wandb>=0.13.5->transformer_lens) (1.3.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\mqtyor\\ai_pc\\envs_general\\cmpttv\\lib\\site-packages (from wandb>=0.13.5->transformer_lens) (69.5.1)\n",
      "Requirement already satisfied: appdirs>=1.4.3 in c:\\users\\mqtyor\\ai_pc\\envs_general\\cmpttv\\lib\\site-packages (from wandb>=0.13.5->transformer_lens) (1.4.4)\n",
      "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in c:\\users\\mqtyor\\ai_pc\\envs_general\\cmpttv\\lib\\site-packages (from wandb>=0.13.5->transformer_lens) (4.23.3)\n",
      "Requirement already satisfied: six>=1.4.0 in c:\\users\\mqtyor\\ai_pc\\envs_general\\cmpttv\\lib\\site-packages (from docker-pycreds>=0.4.0->wandb>=0.13.5->transformer_lens) (1.16.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\mqtyor\\ai_pc\\envs_general\\cmpttv\\lib\\site-packages (from aiohttp->datasets>=2.7.1->transformer_lens) (22.2.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in c:\\users\\mqtyor\\ai_pc\\envs_general\\cmpttv\\lib\\site-packages (from aiohttp->datasets>=2.7.1->transformer_lens) (2.1.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\mqtyor\\ai_pc\\envs_general\\cmpttv\\lib\\site-packages (from aiohttp->datasets>=2.7.1->transformer_lens) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\users\\mqtyor\\ai_pc\\envs_general\\cmpttv\\lib\\site-packages (from aiohttp->datasets>=2.7.1->transformer_lens) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\mqtyor\\ai_pc\\envs_general\\cmpttv\\lib\\site-packages (from aiohttp->datasets>=2.7.1->transformer_lens) (1.8.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\mqtyor\\ai_pc\\envs_general\\cmpttv\\lib\\site-packages (from aiohttp->datasets>=2.7.1->transformer_lens) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\mqtyor\\ai_pc\\envs_general\\cmpttv\\lib\\site-packages (from aiohttp->datasets>=2.7.1->transformer_lens) (1.3.1)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in c:\\users\\mqtyor\\ai_pc\\envs_general\\cmpttv\\lib\\site-packages (from GitPython!=3.1.29,>=1.0.0->wandb>=0.13.5->transformer_lens) (4.0.11)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\mqtyor\\ai_pc\\envs_general\\cmpttv\\lib\\site-packages (from importlib-metadata>=3.6->typeguard<5.0,>=4.2->transformer_lens) (3.15.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\mqtyor\\ai_pc\\envs_general\\cmpttv\\lib\\site-packages (from markdown-it-py<3.0.0,>=2.2.0->rich>=12.6.0->transformer_lens) (0.1.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\mqtyor\\ai_pc\\envs_general\\cmpttv\\lib\\site-packages (from requests>=2.19.0->datasets>=2.7.1->transformer_lens) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\mqtyor\\ai_pc\\envs_general\\cmpttv\\lib\\site-packages (from requests>=2.19.0->datasets>=2.7.1->transformer_lens) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\mqtyor\\ai_pc\\envs_general\\cmpttv\\lib\\site-packages (from requests>=2.19.0->datasets>=2.7.1->transformer_lens) (2024.2.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\mqtyor\\ai_pc\\envs_general\\cmpttv\\lib\\site-packages (from jinja2->torch!=2.0,!=2.1.0,>=1.10->transformer_lens) (2.1.2)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in c:\\users\\mqtyor\\ai_pc\\envs_general\\cmpttv\\lib\\site-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb>=0.13.5->transformer_lens) (5.0.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\mqtyor\\ai_pc\\envs_general\\cmpttv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\mqtyor\\ai_pc\\envs_general\\cmpttv\\lib\\site-packages)\n",
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install transformer_lens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98bc3abd-c0d6-4f8e-b618-ddbb101d5b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any\n",
    "\n",
    "from tqdm import tqdm\n",
    "import einops\n",
    "import numpy as np\n",
    "import torch\n",
    "from datasets import Dataset, IterableDataset, load_dataset\n",
    "from numpy.typing import NDArray\n",
    "from pydantic import BaseModel, ConfigDict\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "# from e2e_sae.types import Samples\n",
    "# from e2e_sae.models.transformers import SAETransformer\n",
    "# from e2e_sae.loader import load_tlens_model\n",
    "\n",
    "from transformer_lens import HookedTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "00ee47fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = HookedTransformer.from_pretrained(\"tiny-stories-1M\")\n",
    "# _logits, cache = model.run_with_cache(\"Some prompt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f913d3da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cache['blocks.0.hook_mlp_out'][0][0]\n",
    "# cache['blocks.0.hook_resid_mid'][0][0]\n",
    "# cache['blocks.0.hook_mlp_out'][0][0]\n",
    "# cache['blocks.0.hook_resid_mid'][0][0] + cache['blocks.0.hook_mlp_out'][0][0]\n",
    "# cache['blocks.0.hook_resid_post'][0][0], \\\n",
    "# cache['blocks.1.hook_resid_pre'][0][0],"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e5252b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list(cache.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "285de65a-9ff7-44c4-981d-f15a08cce11a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetConfig(BaseModel):\n",
    "    model_config = ConfigDict(extra=\"forbid\", frozen=True)\n",
    "    dataset_name: str\n",
    "    is_tokenized: bool = True\n",
    "    tokenizer_name: str\n",
    "    streaming: bool = True\n",
    "    split: str\n",
    "    n_ctx: int\n",
    "    seed: int = 0\n",
    "    column_name: str = \"input_ids\"\n",
    "    \"\"\"The name of the column in the dataset that contains the data (tokenized or non-tokenized).\n",
    "    Typically 'input_ids' for datasets stored with e2e_sae/scripts/upload_hf_dataset.py, or \"tokens\"\n",
    "    for datasets tokenized in TransformerLens (e.g. NeelNanda/pile-10k).\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1737e153-5fac-4441-a8fe-2fe9d5fee9e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_data_loader_only_activations(\n",
    "#     dataset_config: DatasetConfig, batch_size: int, buffer_size: int = 1000, global_seed: int = 0\n",
    "# ) -> tuple[DataLoader, AutoTokenizer]:\n",
    "#     \"\"\"Create a DataLoader for the given dataset.\n",
    "\n",
    "#     Args:\n",
    "#         dataset_config: The configuration for the dataset.\n",
    "#         batch_size: The batch size.\n",
    "#         buffer_size: The buffer size for streaming datasets.\n",
    "#         global_seed: Used for shuffling if dataset_config.seed is None.\n",
    "\n",
    "#     Returns:\n",
    "#         A tuple of the DataLoader and the tokenizer.\n",
    "#     \"\"\"\n",
    "#     dataset = load_dataset(\n",
    "#         dataset_config.dataset_name, streaming=dataset_config.streaming, split=dataset_config.split\n",
    "#     )\n",
    "#     seed = dataset_config.seed if dataset_config.seed is not None else global_seed\n",
    "#     if dataset_config.streaming:\n",
    "#         assert isinstance(dataset, IterableDataset)\n",
    "#         # dataset = dataset.shuffle(seed=seed, buffer_size=buffer_size)\n",
    "#     else:\n",
    "#         # dataset = dataset.shuffle(seed=seed)\n",
    "#         pass\n",
    "\n",
    "#     tokenizer = AutoTokenizer.from_pretrained(dataset_config.tokenizer_name)\n",
    "#     torch_dataset: Dataset\n",
    "#     if dataset_config.is_tokenized:\n",
    "#         torch_dataset = dataset.with_format(\"torch\")  # type: ignore\n",
    "#         # Get a sample from the dataset and check if it's tokenized and what the n_ctx is\n",
    "#         # Note that the dataset may be streamed, so we can't just index into it\n",
    "#         sample = next(iter(torch_dataset))[dataset_config.column_name]  # type: ignore\n",
    "#         assert (\n",
    "#             isinstance(sample, torch.Tensor) and sample.ndim == 1\n",
    "#         ), \"Expected the dataset to be tokenized.\"\n",
    "#         assert len(sample) == dataset_config.n_ctx, \"n_ctx does not match the tokenized length.\"\n",
    "\n",
    "#     else:\n",
    "#         torch_dataset = tokenize_and_concatenate(\n",
    "#             dataset,  # type: ignore\n",
    "#             tokenizer,\n",
    "#             max_length=dataset_config.n_ctx,\n",
    "#             add_bos_token=True,\n",
    "#         )\n",
    "\n",
    "#     # Note that a pre-tokenized dataset was shuffled when generated\n",
    "#     # see e2e_sae.scripts.upload_hf_dataset.TextDataset.__init__\n",
    "#     loader = DataLoader(\n",
    "#         torch_dataset,  # type: ignore\n",
    "#         batch_size=batch_size,\n",
    "#         shuffle=False,\n",
    "#     )\n",
    "#     return loader, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7ec43a0c-73a1-41c6-a8aa-f3beccb655a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_config  = DatasetConfig\n",
    "\n",
    "dataset_config.model_config = None # blank\n",
    "dataset_config.dataset_name= 'roneneldan/TinyStories' # 'apollo-research/roneneldan-TinyStories-tokenizer-gpt2'\n",
    "dataset_config.is_tokenized= False # True\n",
    "dataset_config.tokenizer_name= 'gpt2'\n",
    "dataset_config.streaming= True # True - means you do not download the dataset https://huggingface.co/docs/datasets/en/stream\n",
    "dataset_config.split= 'train' # ['train', 'validation']\n",
    "dataset_config.n_ctx= 512\n",
    "dataset_config.seed= 0\n",
    "dataset_config.column_name: str = \"input_ids\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5e197b9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\MQTyor\\ai_pc\\ENVS_general\\cmpttv\\lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model tiny-stories-1M into HookedTransformer\n",
      "Moving model to device:  cuda\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' # 'cpu', 'cuda'\n",
    "model = HookedTransformer.from_pretrained(\"tiny-stories-1M\").to(device)\n",
    "dataset = load_dataset(\n",
    "    dataset_config.dataset_name, streaming=dataset_config.streaming, split=dataset_config.split\n",
    ")\n",
    "# tokenizer = AutoTokenizer.from_pretrained(dataset_config.tokenizer_name) # 'gpt2' for tiny-stories-1M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d46f3ba2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 1446/3200 [00:31<00:37, 46.45it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 22\u001b[0m\n\u001b[0;32m     20\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m---> 22\u001b[0m     logits_, cache_ \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_with_cache\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext_\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m acts_ \u001b[38;5;241m=\u001b[39m cache_[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mblocks.5.hook_resid_post\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()[\u001b[38;5;241m1\u001b[39m:] \u001b[38;5;66;03m# Skip BOS token\u001b[39;00m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# Append to lists\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\MQTyor\\ai_pc\\ENVS_general\\cmpttv\\lib\\site-packages\\transformer_lens\\HookedTransformer.py:658\u001b[0m, in \u001b[0;36mHookedTransformer.run_with_cache\u001b[1;34m(self, return_cache_object, remove_batch_dim, *model_args, **kwargs)\u001b[0m\n\u001b[0;32m    641\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun_with_cache\u001b[39m(\n\u001b[0;32m    642\u001b[0m     \u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39mmodel_args, return_cache_object\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, remove_batch_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    643\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    650\u001b[0m     Union[ActivationCache, Dict[\u001b[38;5;28mstr\u001b[39m, torch\u001b[38;5;241m.\u001b[39mTensor]],\n\u001b[0;32m    651\u001b[0m ]:\n\u001b[0;32m    652\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Wrapper around `run_with_cache` in HookedRootModule.\u001b[39;00m\n\u001b[0;32m    653\u001b[0m \n\u001b[0;32m    654\u001b[0m \u001b[38;5;124;03m    If return_cache_object is True, this will return an ActivationCache object, with a bunch of\u001b[39;00m\n\u001b[0;32m    655\u001b[0m \u001b[38;5;124;03m    useful HookedTransformer specific methods, otherwise it will return a dictionary of\u001b[39;00m\n\u001b[0;32m    656\u001b[0m \u001b[38;5;124;03m    activations as in HookedRootModule.\u001b[39;00m\n\u001b[0;32m    657\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 658\u001b[0m     out, cache_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrun_with_cache(\n\u001b[0;32m    659\u001b[0m         \u001b[38;5;241m*\u001b[39mmodel_args, remove_batch_dim\u001b[38;5;241m=\u001b[39mremove_batch_dim, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    660\u001b[0m     )\n\u001b[0;32m    661\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m return_cache_object:\n\u001b[0;32m    662\u001b[0m         cache \u001b[38;5;241m=\u001b[39m ActivationCache(cache_dict, \u001b[38;5;28mself\u001b[39m, has_batch_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;129;01mnot\u001b[39;00m remove_batch_dim)\n",
      "File \u001b[1;32mc:\\Users\\MQTyor\\ai_pc\\ENVS_general\\cmpttv\\lib\\site-packages\\transformer_lens\\hook_points.py:566\u001b[0m, in \u001b[0;36mHookedRootModule.run_with_cache\u001b[1;34m(self, names_filter, device, remove_batch_dim, incl_bwd, reset_hooks_end, clear_contexts, pos_slice, *model_args, **model_kwargs)\u001b[0m\n\u001b[0;32m    552\u001b[0m cache_dict, fwd, bwd \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_caching_hooks(\n\u001b[0;32m    553\u001b[0m     names_filter,\n\u001b[0;32m    554\u001b[0m     incl_bwd,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    557\u001b[0m     pos_slice\u001b[38;5;241m=\u001b[39mpos_slice,\n\u001b[0;32m    558\u001b[0m )\n\u001b[0;32m    560\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhooks(\n\u001b[0;32m    561\u001b[0m     fwd_hooks\u001b[38;5;241m=\u001b[39mfwd,\n\u001b[0;32m    562\u001b[0m     bwd_hooks\u001b[38;5;241m=\u001b[39mbwd,\n\u001b[0;32m    563\u001b[0m     reset_hooks_end\u001b[38;5;241m=\u001b[39mreset_hooks_end,\n\u001b[0;32m    564\u001b[0m     clear_contexts\u001b[38;5;241m=\u001b[39mclear_contexts,\n\u001b[0;32m    565\u001b[0m ):\n\u001b[1;32m--> 566\u001b[0m     model_out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m(\u001b[38;5;241m*\u001b[39mmodel_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs)\n\u001b[0;32m    567\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m incl_bwd:\n\u001b[0;32m    568\u001b[0m         model_out\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[1;32mc:\\Users\\MQTyor\\ai_pc\\ENVS_general\\cmpttv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\MQTyor\\ai_pc\\ENVS_general\\cmpttv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\MQTyor\\ai_pc\\ENVS_general\\cmpttv\\lib\\site-packages\\transformer_lens\\HookedTransformer.py:576\u001b[0m, in \u001b[0;36mHookedTransformer.forward\u001b[1;34m(self, input, return_type, loss_per_token, prepend_bos, padding_side, start_at_layer, tokens, shortformer_pos_embed, attention_mask, stop_at_layer, past_kv_cache)\u001b[0m\n\u001b[0;32m    571\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m shortformer_pos_embed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    572\u001b[0m         shortformer_pos_embed \u001b[38;5;241m=\u001b[39m shortformer_pos_embed\u001b[38;5;241m.\u001b[39mto(\n\u001b[0;32m    573\u001b[0m             devices\u001b[38;5;241m.\u001b[39mget_device_for_block_index(i, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcfg)\n\u001b[0;32m    574\u001b[0m         )\n\u001b[1;32m--> 576\u001b[0m     residual \u001b[38;5;241m=\u001b[39m \u001b[43mblock\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    577\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresidual\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    578\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Cache contains a list of HookedTransformerKeyValueCache objects, one for each\u001b[39;49;00m\n\u001b[0;32m    579\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# block\u001b[39;49;00m\n\u001b[0;32m    580\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_kv_cache_entry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_kv_cache\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpast_kv_cache\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    581\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshortformer_pos_embed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshortformer_pos_embed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    582\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    583\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# [batch, pos, d_model]\u001b[39;00m\n\u001b[0;32m    585\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m stop_at_layer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    586\u001b[0m     \u001b[38;5;66;03m# When we stop at an early layer, we end here rather than doing further computation\u001b[39;00m\n\u001b[0;32m    587\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m residual\n",
      "File \u001b[1;32mc:\\Users\\MQTyor\\ai_pc\\ENVS_general\\cmpttv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\MQTyor\\ai_pc\\ENVS_general\\cmpttv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\MQTyor\\ai_pc\\ENVS_general\\cmpttv\\lib\\site-packages\\transformer_lens\\components\\transformer_block.py:160\u001b[0m, in \u001b[0;36mTransformerBlock.forward\u001b[1;34m(self, resid_pre, shortformer_pos_embed, past_kv_cache_entry, attention_mask)\u001b[0m\n\u001b[0;32m    153\u001b[0m     key_input \u001b[38;5;241m=\u001b[39m attn_in\n\u001b[0;32m    154\u001b[0m     value_input \u001b[38;5;241m=\u001b[39m attn_in\n\u001b[0;32m    156\u001b[0m attn_out \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    157\u001b[0m     \u001b[38;5;66;03m# hook the residual stream states that are used to calculate the\u001b[39;00m\n\u001b[0;32m    158\u001b[0m     \u001b[38;5;66;03m# queries, keys and values, independently.\u001b[39;00m\n\u001b[0;32m    159\u001b[0m     \u001b[38;5;66;03m# Then take the layer norm of these inputs, and pass these to the attention module.\u001b[39;00m\n\u001b[1;32m--> 160\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    161\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquery_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mln1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    162\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mshortformer_pos_embed\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mshortformer_pos_embed\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    163\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkey_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mln1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    164\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mshortformer_pos_embed\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mshortformer_pos_embed\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    165\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalue_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mln1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue_input\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    166\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_kv_cache_entry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_kv_cache_entry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    167\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    168\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    169\u001b[0m )  \u001b[38;5;66;03m# [batch, pos, d_model]\u001b[39;00m\n\u001b[0;32m    170\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcfg\u001b[38;5;241m.\u001b[39muse_normalization_before_and_after:\n\u001b[0;32m    171\u001b[0m     \u001b[38;5;66;03m# If we use LayerNorm both before and after, then apply the second LN after the layer\u001b[39;00m\n\u001b[0;32m    172\u001b[0m     \u001b[38;5;66;03m# and before the hook. We do it before the hook so hook_attn_out captures \"that which\u001b[39;00m\n\u001b[0;32m    173\u001b[0m     \u001b[38;5;66;03m# is added to the residual stream\"\u001b[39;00m\n\u001b[0;32m    174\u001b[0m     attn_out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mln1_post(attn_out)\n",
      "File \u001b[1;32mc:\\Users\\MQTyor\\ai_pc\\ENVS_general\\cmpttv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\MQTyor\\ai_pc\\ENVS_general\\cmpttv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\MQTyor\\ai_pc\\ENVS_general\\cmpttv\\lib\\site-packages\\transformer_lens\\components\\abstract_attention.py:260\u001b[0m, in \u001b[0;36mAbstractAttention.forward\u001b[1;34m(self, query_input, key_input, value_input, past_kv_cache_entry, additive_attention_mask, attention_mask, position_bias)\u001b[0m\n\u001b[0;32m    258\u001b[0m attn_scores \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhook_attn_scores(attn_scores)\n\u001b[0;32m    259\u001b[0m pattern \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39msoftmax(attn_scores, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m--> 260\u001b[0m pattern \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwhere\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43misnan\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpattern\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzeros_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpattern\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpattern\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    261\u001b[0m pattern \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhook_pattern(pattern)  \u001b[38;5;66;03m# [batch, head_index, query_pos, key_pos]\u001b[39;00m\n\u001b[0;32m    262\u001b[0m pattern \u001b[38;5;241m=\u001b[39m pattern\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcfg\u001b[38;5;241m.\u001b[39mdtype)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Gather hidden representations of the residual stream after the block  blocks.5\n",
    "    blocks.5.hook_resid_post\n",
    "\"\"\"\n",
    "\n",
    "n_seqs = 3200 # 3200 # Num sequences to process\n",
    "embs_list = []\n",
    "tokens_list = []\n",
    "text_id_list = []\n",
    "seqs_saved = []\n",
    "for i, v in tqdm(enumerate(dataset), total=n_seqs):\n",
    "    # print(v)\n",
    "    text_ = v['text']\n",
    "    # print(text_)\n",
    "    # tokenized = tokenizer(text_)['input_ids']\n",
    "    # print(tokenized)\n",
    "    # decoded = tokenizer.decode(tokenized)\n",
    "    # print(decoded)\n",
    "    tokenized = model.tokenizer(text_)['input_ids'] # No BOS token\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        logits_, cache_ = model.run_with_cache(text_)\n",
    "    acts_ = cache_['blocks.5.hook_resid_post'][0].cpu().numpy()[1:] # Skip BOS token\n",
    "    # Append to lists\n",
    "    embs_list.append(acts_)\n",
    "    tokens_list.append(tokenized)\n",
    "    text_id_list = text_id_list + [i]*len(acts_)\n",
    "    seqs_saved.append(text_)\n",
    "    if i >= n_seqs:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ba228b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "embs_flat = np.array([v for vv in embs_list for v in vv])\n",
    "tokens_str_list_flat = [model.tokenizer.decode(v) for vv in tokens_list for v in vv]\n",
    "assert (len(embs_flat)==len(tokens_str_list_flat)==len(text_id_list)), 'Not equal len'\n",
    "\n",
    "# Save embedding matrix\n",
    "print(f\"Embedding matrix takes {embs_flat.nbytes/1024**2:.3f} Mb\")\n",
    "datadir = Path ('./')\n",
    "filepath_acts = datadir / f\"emb_matrix.npy\"\n",
    "with open(filepath_acts, 'wb') as f:\n",
    "    np.save(f, embs_flat)\n",
    "\n",
    "df_acts_tokens = pd.DataFrame()\n",
    "df_acts_tokens['emb_id'] = list(range(len(embs_flat)))\n",
    "df_acts_tokens['token_str'] = tokens_str_list_flat\n",
    "df_acts_tokens['seq_id'] = text_id_list\n",
    "df_acts_tokens.emb_id = df_acts_tokens.emb_id.astype(np.int32)\n",
    "# df_acts_tokens.token = df_acts_tokens.token.astype(np.int32)\n",
    "df_acts_tokens.seq_id = df_acts_tokens.seq_id.astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a07e015d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emb_id</th>\n",
       "      <th>token_str</th>\n",
       "      <th>seq_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>One</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>day</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>,</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>a</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>little</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   emb_id token_str  seq_id\n",
       "0       0       One       0\n",
       "1       1       day       0\n",
       "2       2         ,       0\n",
       "3       3         a       0\n",
       "4       4    little       0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_acts_tokens.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "093df139",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Play with sorting tokens by neuron activations\n",
    "# qq = np.array(acts_list_flat)\n",
    "# df_acts_tokens['nn'] = qq[:, 1]\n",
    "# df_acts_tokens.sort_values(by='nn', ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "203d1632",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the dataset of texts activations have been acquired from\n",
    "df_texts = pd.DataFrame()\n",
    "df_texts['seq'] = seqs_saved\n",
    "df_texts['seq_id'] = df_texts.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "10cc0cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Left join activations dataframe with sequence dataframe\n",
    "# df_acts_tokens.merge(df_texts, how='left', on='seq_id').info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ab8acd2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 682595 entries, 0 to 682594\n",
      "Data columns (total 3 columns):\n",
      " #   Column     Non-Null Count   Dtype \n",
      "---  ------     --------------   ----- \n",
      " 0   emb_id     682595 non-null  int32 \n",
      " 1   token_str  682595 non-null  object\n",
      " 2   seq_id     682595 non-null  int32 \n",
      "dtypes: int32(2), object(1)\n",
      "memory usage: 10.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df_acts_tokens.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5866a743",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3201 entries, 0 to 3200\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   seq     3201 non-null   object\n",
      " 1   seq_id  3201 non-null   int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 50.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df_texts.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2bbb3f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_acts_tokens.to_csv(datadir / \"tinystories1M-TinyStories1_gpt2token-acts_id.csv\", index=False)\n",
    "df_texts.to_csv(datadir / \"tinystories1M-TinyStories1_gpt2token-texts.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac238f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "del df_acts_tokens\n",
    "del df_texts\n",
    "del embs_flat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "101f81b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pathlib import Path\n",
    "# datadir = Path(\"./\")\n",
    "\n",
    "# # Load DataFrames with embedding ids and texts\n",
    "# df_acts_filename = datadir / \"tinystories1M-TinyStories1_gpt2token-acts_id.csv\"\n",
    "# df_texts_filename = datadir / \"tinystories1M-TinyStories1_gpt2token-texts.csv\"\n",
    "# df_acts_tokens = pd.read_csv(df_acts_filename)\n",
    "# df_texts= pd.read_csv(df_texts_filename)\n",
    "\n",
    "# # Load embedding matrix\n",
    "# with open(datadir / 'emb_matrix.npy', 'rb') as f:\n",
    "#     embs_flat = np.load(f)\n",
    "    \n",
    "# # # Left join activations dataframe with sequence dataframe\n",
    "# # df_acts_tokens_texts = df_acts_tokens.merge(df_texts, how='left', on='seq_id').info()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cmpttv-jup",
   "language": "python",
   "name": "cmpttv-jup"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
